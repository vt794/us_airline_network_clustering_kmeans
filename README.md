# Exploring U.S. Airline Networks via the DB1B Ticketing Data Set Using KMeans Clustering

This repository proposes a workflow for identifying patterns among Origin-Destination (OD) pairs from a sample of quarterly ticketing data reported by U.S. carriers to the Bureau of Transportation Statistics. Based upon commercial and geographical filters of interest specified by the user, it groups OD pairs into clusters that reflect patterns identified within the underlying feature space.

## The Data Set

The United States' Department of Transportation's Bureau of Transportation Statistics maintains a series of transportation data sets made available for academic research. The Airline Origin and Destination Survey (DB1B) data set comprises quarterly ticketing data reported by U.S. airlines to the Bureau of Transportation Statistics, stored in relational database-like form in $3$ relational tables: `DB1BCoupon`, `DB1BMarket`, and `DB1BTicket`. 

Importantly, it is a sample representing 10% of nearly all tickets sold by reporting carriers, selected by retaining those tickets whose itinerary identifier's last digit is $0$. Complete DB1B population data may be requested by U.S. citizens who have received authorization from DOT. This has implications for any insight gathered from this workflow: the relevance of its proposed systematic pre-processing and modeling workflow outweights any granular commercial findings it may produce. 

N.b., DB1B data is made available exclusively for academic research, and its use for consulting or for-profit activities is not permitted under the terms of use. This repository is strictly academic in nature. 

For more information: 
- the Bureau of Transportation Statistics DB1B data documentation can be found [here](https://www.transtats.bts.gov/Tables.asp?QO_VQ=EFI&QO_anzr=Nv4yv0r%FDb4vtv0%FDn0q%FDQr56v0n6v10%FDf748rB%FD%FLQOEO%FM&QO_fu146_anzr=b4vtv0%FDn0q%FDQr56v0n6v10%FDf748rB]), and
- the National Bureau of Economic Research (NBER) describes DB1A/DB1B at length [here](https://www.nber.org/research/data/department-transportation-db1adb1b).

## Data Processing and Modeling Approach

This workflow follows a sequence of four steps, each encompassed within its own script:
- `download.py` downloads DB1B ticket, coupon, and market data for the quarter and year specified by the user,
- `preprocess.py` applies data transformations that produce ticket-indexed feature data,
- `filter_aggregate.py` filters tickets as specified by the user, and aggregates them to non-directional OD-indexed observations,
- `model.py` passes the resulting aggregated and filtered as input to a KMeans unsupervised learning algorithm that assigns a label to every non-directional OD-indexed data observation, separating them among $k$ clusters (defined optimally in systematic manner or specified by the user).  

A KMeans modeling framework is favored for this particular application for its relatively systematic implementation and intuitive underlying algorithm. Assigning exactly one label per every observation, it separates observations among $k$ clusters of more-or-less equal feature space variance, minimizing the inertia criterion, defined as the within-cluster sum-of-squares, the sum of the square distances between observations in a given cluster and the cluster centroid.

In addition, while unsupervised clustering is notorious for offering no objective model performance criterion, the Elbow plot - which visualizes the within-cluster sum-of-squares per every candidate $k$ - can be used as a systematic approach to select a optimal-like hyper-parameter $k$. Alternatively, this workflow gives the user the ability to pass a value for $k$ of their choice as parameter.

## Output

The output generated by the model, saved to the `data/results` folder, includes the following:
1. a summary statistics table summarizing the cluster to which observations were assigned (saved as .csv file),
2. a Elbow, a Silhouette, and a 2-dimensional PCA plot as proxy for overall model performance (saved as .png file), 
3. a full outline of the non-directional OD feature space along with its respective cluster assingment (saved as .csv file).

## Interpretation

The minimal structure of this repository promotes independent exploratory investigation and interpretation by the user. General interpretation advice is limited to the following:
1. select a research question and formulate command paramters accordingly, 
2. explore resulting plots and summary table data to subjectively assess the quality (i.e., relevance) of the model output, and
3. investigate per-observation assigned labels to point to any meaningful patterns and commercial insight.

## Usage via Command Line

The following two-step process allows using this workflow iteratively. **Step 1** is to be repeated only if a new date period is to be investigated, while **Step 2** can be repeated by varying its parameters for exploratory purposes. 

- **Step 1** creates a virtual environment based on `requirements.txt`, then downloads and pre-processes DB1B data for the quarter and year specified by the user. Simply execute the following command from the root directory:

```
make data year=<year> quarter=<quarter>
```

| Parameter    | Mandatory/Optional | Syntax |
| ------------ | ------------------ | ------ |
| year         | Mandatory          | int: 4-digit format (e.g., `2019`) |
| quarter      | Mandatory          | int: 1-digit format (e.g., `3`) |

- **Step 2** aggregates and filters the preprocessed data based on any investigation needs identified by the user (n.b., all arguments are optional):

```
make model [options]
```

| Parameter    | Mandatory/Optional | Syntax |
| ------------ | ------------------ | ------ |
| state        | Optional           | str: 2-letter abbreviation, capitalized, comma-separated for multiples (e.g., `NY` or `CA,TX`) |
| airport      | Optional           | str: 3-letter code, capitalized, comma-separated for multiples (e.g., `EWR` or `DCA,SEA`) |
| rpcarrier    | Optional           | str: 2-char airline code, capitalized, comma-separated for multiples (e.g., `AA` or `DL,UA`) |
| roundtrip    | Optional           | boolean (`True` or `False`) |
| distance_max | Optional           | int: integer numeric, no punctation (e.g., `2500`) |
| distance_min | Optional           | int: integer numeric, no punctation (e.g., `800`) |
| n_clusters   | Optional           | int: integer numeric, no punctation (e.g., `5`) |

For help for either command, such as the format of its parameters, execute:
```
make <command> --help
```

#### Example

To explore DB1B data for Q3 2019 for patterns among passenger non-directional one-way traffic between EWR, DCA, and BOS, and the state of California, among reporting carriers AA, UA, and DL:
```
make data year=2019 quarter=3
make model airport=EWR,DCA,BOS state=CA rpcarrier=AA,UA,DL roudtrip=False
```

Note, for better model performance and more interpretable results, it is advisable not to leave `make model` params unspecified. Rather, it is recommended to pick scope for exploratory investigation, and assess results iteratively. 

## Limitations and Contributions

Insight from a machine learning model can only be as relevant as the input feature data it is trained on. From an analysis standpoint, DB1B data is interesting partly thanks to its uniform data collection across carriers, though it does not permit engineering features from more granular ticket data, such as day-of-week and booking advance purchase patterns. 

Possible avenues for further improvement to this workflow may include:
- building other creative features that may better convey insight during analysis, and taking a systematic approach for feature selection,
- exploring a different clustering model architecture, or
- augmenting currently used data with novel databases.

Contributions are welcome. Please either fork this repo for own development needs, or clone it and open an issue with proposed changes:

```
git clone https://github.com/vt794/bots_od_clustering
```
